{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMD0n+TnU5m++g2YFaJGP2I"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FZeVVE5dVfHQ","executionInfo":{"status":"ok","timestamp":1721302915522,"user_tz":-330,"elapsed":576,"user":{"displayName":"Anitha B","userId":"02904034146350906953"}},"outputId":"ec8af95f-0b15-479b-d2e8-a4e8750fad36"},"outputs":[{"output_type":"stream","name":"stdout","text":["Title: The Dormouse's story\n","Paragraph title: Once upon a time there were three little sisters; and their names were\n","      Elsie,\n","      Lacie and\n","      Tillie;\n","      and they lived at the bottom of a well.\n","Link: http://example.com/elsie - Text: Elsie\n","Link: http://example.com/lacie - Text: Lacie\n","Link: http://example.com/tillie - Text: Tillie\n"]}],"source":["from bs4 import BeautifulSoup\n","\n","# Sample HTML document\n","html_doc = \"\"\"\n","<html>\n","  <head>\n","    <title>The Dormouse's story</title>\n","  </head>\n","  <body>\n","    <h1>Chapter 1</h1>\n","    <p class=\"title\"><b>The Dormouse's story</b></p>\n","    <p class=\"story\">Once upon a time there were three little sisters; and their names were\n","      <a href=\"http://example.com/elsie\" class=\"sister\" id=\"link1\">Elsie</a>,\n","      <a href=\"http://example.com/lacie\" class=\"sister\" id=\"link2\">Lacie</a> and\n","      <a href=\"http://example.com/tillie\" class=\"sister\" id=\"link3\">Tillie</a>;\n","      and they lived at the bottom of a well.</p>\n","    <p class=\"story\">...</p>\n","  </body>\n","</html>\n","\"\"\"\n","\n","# Create a BeautifulSoup object\n","soup = BeautifulSoup(html_doc, 'html.parser')\n","\n","# Extract the title\n","title = soup.title.string\n","print(f\"Title: {title}\")\n","\n","# Extract the first <p> tag with class \"title\"\n","p_title = soup.find('p', class_='story').get_text()\n","print(f\"Paragraph title: {p_title}\")\n","\n","# Extract all links\n","links = soup.find_all('a')\n","for link in links:\n","    print(f\"Link: {link.get('href')} - Text: {link.string}\")\n"]},{"cell_type":"code","source":["# pip install requests beautifulsoup4\n","\n","import requests\n","from bs4 import BeautifulSoup\n","\n","# URL of the page to be scraped\n","url = \"http://olympus.realpython.org/profiles/dionysus\"\n","\n","# Send a GET request to the webpage\n","response = requests.get(url)\n","\n","# Check if the request was successful\n","if response.status_code == 200:\n","    # Parse the page content\n","    soup = BeautifulSoup(response.content, 'html.parser')\n","\n","    title = soup.title.string if soup.title else 'No title found'\n","    print(f\"Title: {title}\")\n","\n","    # Extract and print specific data with error handling\n","    name_tag = soup.find('h2', string='Name:')\n","    favorite_color_tag = soup.find('h2', string='Favorite Color:')\n","\n","    name = name_tag.find_next_sibling('h2').get_text() if name_tag else 'Name not found'\n","    favorite_color = favorite_color_tag.find_next_sibling('h2').get_text() if favorite_color_tag else 'Favorite Color not found'\n","    # name = soup.find('h2', string='Name:').find_next_sibling('p').get_text()\n","    # favorite_color = soup.find('h2', string='Favorite Color:').find_next_sibling('p').get_text()\n","\n","\n","    print(f\"Name: {name}\")\n","    print(f\"Favorite Color: {favorite_color}\")\n","else:\n","    print(f\"Failed to retrieve the webpage. Status code: {response.status_code}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_vWv5ml3Xs_z","executionInfo":{"status":"ok","timestamp":1721302916164,"user_tz":-330,"elapsed":643,"user":{"displayName":"Anitha B","userId":"02904034146350906953"}},"outputId":"9e436558-ae05-4be2-e768-6dd031d47c97"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Title: Profile: Dionysus\n","Name: Name not found\n","Favorite Color: Favorite Color not found\n"]}]},{"cell_type":"code","source":["import requests\n","from bs4 import BeautifulSoup\n","\n","# URL of the page to be scraped\n","\n","# Fetch the page content using requests\n","response = requests.get(url)\n","\n","# Check if url = \"http://olympus.realpython.org/profiles/dionysus\"\n","the request was successful\n","if response.status_code == 200:\n","    # Parse the page content with BeautifulSoup\n","    soup = BeautifulSoup(response.content, 'html.parser')\n","\n","    # Extract and print the title\n","    title = soup.title.string if soup.title else 'No title found'\n","    print(f\"Title: {title}\")\n","\n","    # Extract specific data\n","    name_tag = soup.find('h2', string=lambda text: 'Name:' in text)\n","    if name_tag:\n","        name = name_tag.get_text().split(':')[-1].strip()\n","    else:\n","        name = 'Name not found'\n","\n","    web_text = soup.get_text()\n","    favorite_color = None\n","    Hometown =None\n","    for line in web_text.split('\\n'):\n","        if 'Favorite Color:' in line:\n","            favorite_color = line.split(':')[-1].strip()\n","            break\n","\n","    for line in web_text.split('\\n'):\n","        if 'Hometown:' in line:\n","            Hometown = line.split(':')[-1].strip()\n","            break\n","\n","    if not favorite_color:\n","        favorite_color = 'Favorite Color not found'\n","    if not Hometown:\n","        Hometown = 'Hometown is not found'\n","    print(f\"Name: {name}\")\n","    print(f\"Favorite Color: {favorite_color}\")\n","    print(f\"Hometown : {Hometown}\")\n","else:\n","    print(f\"Failed to retrieve the webpage. Status code: {response.status_code}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":110},"id":"s-OR5w10aVFW","executionInfo":{"status":"error","timestamp":1721302916164,"user_tz":-330,"elapsed":5,"user":{"displayName":"Anitha B","userId":"02904034146350906953"}},"outputId":"f9a8f1de-98b2-44ed-cee9-20b2c84acfa9"},"execution_count":3,"outputs":[{"output_type":"error","ename":"SyntaxError","evalue":"invalid syntax (<ipython-input-3-344da6d7eb44>, line 10)","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-3-344da6d7eb44>\"\u001b[0;36m, line \u001b[0;32m10\u001b[0m\n\u001b[0;31m    the request was successful\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"]}]},{"cell_type":"code","source":["from urllib.request import urlopen\n","from bs4 import BeautifulSoup\n","\n","url = \"http://olympus.realpython.org/profiles/dionysus\"\n","\n","html_page = urlopen(url)\n","html_text = html_page.read().decode(\"utf-8\")\n","print(type(html_text))"],"metadata":{"id":"Etbwk_L6Vx-W","executionInfo":{"status":"aborted","timestamp":1721302916164,"user_tz":-330,"elapsed":3,"user":{"displayName":"Anitha B","userId":"02904034146350906953"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Pzx2kWXEfo-E","executionInfo":{"status":"aborted","timestamp":1721302916164,"user_tz":-330,"elapsed":3,"user":{"displayName":"Anitha B","userId":"02904034146350906953"}}},"execution_count":null,"outputs":[]}]}